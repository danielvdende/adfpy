{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to \ud83c\udfed\ud83c\udf70 adfPy","text":"<p>AdfPy is an opinionated, Pythonic wrapper around the Azure Data Factory (ADF) SDK. It aims to provide Airflow-like syntax for defining data pipelines in ADF, making it easier and more reliable to build data pipelines in a robust manner. </p> <p>The documentation here is intended to make easy and clear how to use AdfPy. Please also check out the examples included in the repository.</p>"},{"location":"#key-features-and-principles","title":"Key features and principles","text":"<ul> <li>adfPy does not aim to be 100% feature-complete (at least, not for now). Instead, it exposes the most-used components of ADF. If you do miss something, don't hesitate to contribute! We're more than happy to receive any help.</li> <li>Where possible, we have stuck with a naming convention of prefixing the ADF SDK function/class name with <code>Adf</code>. This makes it clear what part of the SDK we are wrapping, but also ensure it's clear what components are part of adfPy.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We're more than happy to receive any contributions: big, small, or anywhere in between! Please open an issue and a PR on github and we'll get back to you as soon as we can!</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>Installation of adfPy is simple: <pre><code>pip install adfpy\n</code></pre></p> <p>This will give you:</p> <ul> <li>The adfPy classes and functions you need to build awesome pipelines.</li> <li>A CLI command: <code>adfpy-deploy</code> which parses your adfPy resource definitions and ensures they are correctly configured in your ADF instance.</li> </ul>"},{"location":"getting_started/#writing-your-first-adfpy-pipeline","title":"Writing your first adfPy pipeline","text":"<p>For those of you familiar with Airflow, the syntax will (hopefully) look quite similar. To create a simple pipeline in ADF, the following adfPy code can be used: <pre><code>from azure.mgmt.datafactory.models import BlobSource, BlobSink\nfrom adfpy.activities.execution import AdfCopyActivity, AdfDatabricksSparkPythonActivity\nfrom adfpy.pipeline import AdfPipeline\nextract = AdfCopyActivity(\nname=\"copyBlobToBlob\",\ninput_dataset_name=\"staging\",\noutput_dataset_name=\"landing\",\nsource_type=BlobSource,\nsink_type=BlobSink,\n)\ningest = AdfDatabricksSparkPythonActivity(name=\"ingest\", python_file=\"foo.py\")\nextract &gt;&gt; ingest\npipeline = AdfPipeline(name=\"copyPipeline\", activities=[extract, ingest], schedule=\"* * 5 * *\")\n</code></pre></p> <p>There are a few noteworthy things here: 1. All adfPy resources are prefixed with <code>Adf</code>. Other than that, the aim is to keep the naming as much in line with ADF as possible to ensure it's clear what kind of Activity will be created in ADF when you deploy. 2. Dependencies between activities can be set using the bitshift operators (<code>&gt;&gt;</code> and <code>&lt;&lt;</code>). They work exactly the same as they do in Airflow. 3. As in Airflow, you can define the execution schedule as an attribute of the Pipeline. </p> <p>This code is available as an example in the examples directory in the adfPy repository along with more complex cases.</p>"},{"location":"user_guide/custom_activities/","title":"Custom Activities","text":"<p>While we would like to include support for all ADF activities out of the box, we also would like to offer the capability to the users of adfPy to add and customize their own adfPy components. To do this, the easiest way is to check out the source code of the existing AdfActivities.</p> <p>To create a new AdfActivity, in a nutshell, you need to:</p> <ol> <li>Create a class that extends <code>AdfActivity</code></li> <li>Ensure you correctly implement the <code>to_adf</code> method that converts all necessary attributes to ADF objects.</li> </ol> <p>That's it! </p>"},{"location":"user_guide/deploying/","title":"Deploying","text":"<p>Once you've written the code for your adfPy components, it's time to deploy them to ADF! </p> <p>The easiest way to do this is to use the deploy executable that is included in the adfPy package that you installed. To run it: <pre><code>adfpy-deploy --path PATH\n</code></pre> where <code>PATH</code> is the location of your adfPy resources. This includes both pipelines and triggers (and other ADF resources in the future).</p>"},{"location":"user_guide/deploying/#configuration","title":"Configuration","text":"<p>In order to use <code>adfpy-deploy</code>, the following environment variables need to be set:</p> Environment Variable Description Example <code>AZURE_SUBSCRIPTION_ID</code> The id of the subscription in which your ADF instance is. <code>AZURE_RESOURCE_GROUP_NAME</code> The name of the resource group in which your ADF instance is <code>AZURE_DATA_FACTORY_NAME</code> The name of your ADF instance <code>AZURE_SERVICE_PRINCIPAL_CLIENT_ID</code> The client id of the Service Prinicpal you are using. This SP will need sufficient permissions to do XXX with ADF. <code>AZURE_SERVICE_PRINCIPAL_SECRET</code> The corresponding secret for your Service Principal. <code>AZURE_TENANT_ID</code> The tenant id in which your ADF instance is deployed"},{"location":"user_guide/deploying/#disable-resource-removal","title":"Disable resource removal","text":"<p>By default, <code>adfpy-deploy</code> will try to synchronize whatever ADF resources you have in your defined path with whatever is present in the configured ADF instance. To disable this behaviour, add the <code>--no-delete-stale-resources</code> parameter, e.g. <pre><code>adfpy-deploy --path foo --no-delete-stale-resources\n</code></pre> Setting <code>--no-delete-stale-resources</code> will prevent adfPy from removing any existing resources that are not on the configured path, but it will still add or update the resources you have in your path.</p>"},{"location":"user_guide/pipelines/","title":"Pipelines","text":"<p>Pipelines are one of the fundamental building blocks of both ADF and adfPy. To create an AdfPipeline: <pre><code>from adfpy.pipeline import AdfPipeline\npipeline = AdfPipeline(name=\"copyPipeline\", activities=[extract, ingest], schedule=\"* * 5 * *\")\n</code></pre> The only required argument for an AdfPipeline is its name. Adding activities to a AdfPipeline can be done in 2 ways: 1. (As above) pass in a list of AdfActivity objects.  2. Specify the pipeline object as a parameter when creating each AdfActivity (shown below) <pre><code>from adfpy.activities.execution import AdfCopyActivity, AdfDatabricksSparkPythonActivity\nextract = AdfCopyActivity(\nname=\"copyBlobToBlob\",\ninput_dataset_name=\"staging\",\noutput_dataset_name=\"landing\",\nsource_type=BlobSource,\nsink_type=BlobSink,\npipeline=pipeline\n)\ningest = AdfDatabricksSparkPythonActivity(name=\"ingest\", python_file=\"foo.py\", pipeline=pipeline)\n</code></pre> Both approaches will give you exactly the same result when you deploy to ADF.</p> <p>Note also that instead of specifying a separate <code>Trigger</code> resource (which is the approach ADF takes), adfPy allows you to set this on the adfPipeline object. For more information on this, take a look at the Triggers page.</p>"},{"location":"user_guide/pipelines/#setting-dependencies-between-activities","title":"Setting dependencies between activities","text":"<p>Setting dependencies between activities in adfPy is very similar to how Airflow does this using the bitshift operators: <pre><code>activity1 &gt;&gt; activity2\n</code></pre> will create a dependency on <code>activity1</code> for <code>activity2</code>. This can also be used with lists, as in Airflow: <pre><code>activity1 &gt;&gt; [activity2, activity3] &gt;&gt; activity4\n</code></pre> is equivalent to <pre><code>activity1 &gt;&gt; activity2 &gt;&gt; activity4\nactivity1 &gt;&gt; activity3 &gt;&gt; activity4\n</code></pre></p> <p>The implicit assumption here is that the dependency condition between the activities is <code>Succeeded</code>. This means that in the previous examples <code>activity2</code> will only execute if <code>activity1</code> completed successfully. If you want to deviate from this, for example to define failure handling, you can explicitly set dependencies for an activity: <pre><code>activity2.add_dependency(activity_name=\"activity1\", dependency_conditions=[\"Failed\"])\n</code></pre> Possible dependency conditions are the same as in ADF:</p> <ul> <li>Succeeded</li> <li>Failed</li> <li>Skipped</li> <li>Completed</li> </ul>"},{"location":"user_guide/triggers/","title":"Triggers","text":"<p>An important aspect of data pipelines in general (and ADF) is not only the structure of the pipelines, but also when to execute them. adfPy currently supports scheduled triggers (other trigger types are planned to be added in the future). To make life easy, adfPy allows you to use familiar cron-like syntax to specify when the pipeline is to be executed: <pre><code>pipeline = AdfPipeline(name=\"copyPipeline\", schedule=\"* * 5 * *\")\n</code></pre> For figuring out what cron expression to use, we recommend Crontab.guru</p>"},{"location":"user_guide/triggers/#start-dates","title":"Start dates","text":"<p>Naturally, when specifying a schedule it is important to think about what the start date should be. If you do not specify a start date, adfPy will use  <pre><code>datetime.now(tz=timezone.utc)\n</code></pre> It's strongly recommended to set a valid start time yourself. To do this, pass it in as an additional parameter to your Pipeline: <pre><code>pipeline = AdfPipeline(name=\"copyPipeline\", schedule=\"* * 5 * *\", start_time=datetime(2022,7,13,2))\n</code></pre></p>"},{"location":"user_guide/triggers/#unsupported-cron-expressions","title":"Unsupported Cron expressions","text":"<p>Due to ADF's scheduling design, there are a number of cron expressions that unfortunately cannot be supported. The expressions that are not supported are best documented with concrete examples:</p> <p>{\" * 5 * 5\": \"At every minute on day-of-month 5 and on Friday.\"}, {\"5 * 5 * 5\": \"At minute 5 on day-of-month 5 and on Friday.\"}, {\" 5 5 * 5\": \"At every minute past hour 5 on day-of-month 5 and on Friday.\"}, {\"5 5 5 * 5\": \"At 05:05 on day-of-month 5 and on Friday.\"}</p> Cron expression Natural language translation <code>* * 5 * 5</code> At every minute on day-of-month 5 and on Friday. <code>5 * 5 * 5</code> At minute 5 on day-of-month 5 and on Friday. <code>* 5 5 * 5</code> At every minute past hour 5 on day-of-month 5 and on Friday. <code>5 5 5 * 5</code> At 05:05 on day-of-month 5 and on Friday."}]}